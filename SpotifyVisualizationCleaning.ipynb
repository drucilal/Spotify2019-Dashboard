{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Spotify Top Streamed Female & Male Artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Cleaning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  cleaning_module import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Female Artists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari1 = pd.read_csv('ariana1_catalog.csv')\n",
    "ari2 = pd.read_csv('ariana2_catalog.csv')\n",
    "beyonce1 = pd.read_csv('beyonce1_catalog.csv')\n",
    "beyonce2 = pd.read_csv('beyonce2_catalog.csv')\n",
    "rihanna1 = pd.read_csv('rihanna1_catalog.csv')\n",
    "rihanna2 = pd.read_csv('rihanna2_catalog.csv')\n",
    "sia1 = pd.read_csv('sia1_catalog.csv')\n",
    "sia2 = pd.read_csv('sia2_catalog.csv')\n",
    "taylor1 = pd.read_csv('taylorswift1_catalog.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Male Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drake = pd.read_csv('drake_catalog.csv')\n",
    "edsheer = pd.read_csv('edsheeran_catalog.csv')\n",
    "postma = pd.read_csv('postmalone1_catalog.csv')\n",
    "eminem = pd.read_csv('eminem_catalog.csv')\n",
    "weekend1 = pd.read_csv('weekend1_catalog.csv')\n",
    "weekend2 = pd.read_csv('weekend2_catalog.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ariana_grande = pd.concat([ari1, ari2])\n",
    "beyonce = pd.concat([beyonce1, beyonce2])\n",
    "rihanna = pd.concat([rihanna1, rihanna2])\n",
    "sia = pd.concat([sia1, sia2])\n",
    "taylorswift = taylor1\n",
    "weekend = pd.concat([weekend1, weekend2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicates by artist and track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_duplicates_dataset(ariana_grande)\n",
    "drop_duplicates_dataset(beyonce)\n",
    "drop_duplicates_dataset(rihanna)\n",
    "drop_duplicates_dataset(sia)\n",
    "drop_duplicates_dataset(taylorswift)\n",
    "drop_duplicates_dataset(drake)\n",
    "drop_duplicates_dataset(edsheer)\n",
    "drop_duplicates_dataset(postma)\n",
    "drop_duplicates_dataset(eminem)\n",
    "drop_duplicates_dataset(weekend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Part 2: Adding in Feature Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length: converting from milliseconds to minutes\n",
    "\n",
    "Year: extacting the year from the release date  column\n",
    "\n",
    "Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_cleaning(ariana_grande)\n",
    "extra_cleaning(beyonce)\n",
    "extra_cleaning(rihanna)\n",
    "extra_cleaning(sia)\n",
    "extra_cleaning(taylorswift)\n",
    "extra_cleaning(drake)\n",
    "extra_cleaning(edsheer)\n",
    "extra_cleaning(postma)\n",
    "extra_cleaning(eminem)\n",
    "extra_cleaning(weekend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature (boolean): Was this artist featured in one of these songs? True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "beyonce['feature'] = np.where(beyonce['artist']== 'Beyonc√©', 'True', 'False')\n",
    "rihanna['feature'] = np.where(rihanna['artist']== 'Rihanna', 'True', 'False')\n",
    "sia['feature'] = np.where(sia['artist']== 'Sia', 'True', 'False')\n",
    "taylorswift['feature'] = np.where(taylorswift['artist']== 'Taylor Swift', 'True', 'False')\n",
    "drake['feature'] = np.where(drake['artist']== 'Drake', 'True', 'False')\n",
    "edsheer['feature'] = np.where(edsheer['artist']== 'Ed Sheeran', 'True', 'False')\n",
    "postma['feature'] = np.where(postma['artist']== 'Post Malone', 'True', 'False')\n",
    "eminem['feature'] = np.where(eminem['artist']== 'Eminem', 'True', 'False')\n",
    "weekend['feature'] = np.where(weekend['artist']== 'The Weeknd', 'True', 'False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ariana_grande.to_csv(\"arianagrande_catalog\", sep = ',', index = False)\n",
    "beyonce.to_csv('beyonce_catalog', sep = ',', index = False)\n",
    "rihanna.to_csv('rihanna_catalog', sep = ',', index = False)\n",
    "sia.to_csv('sia_catalog', sep = ',', index = False)\n",
    "taylorswift.to_csv('taylorswift_catalog', sep = ',', index = False)\n",
    "drake.to_csv('drake_catalog', sep = ',', index = False)\n",
    "edsheer.to_csv('ed_sheeran_catalog', sep = ',', index = False)\n",
    "postma.to_csv('postmalone_catalog', sep = ',', index = False)\n",
    "eminem.to_csv('eminem_catalog', sep = ',', index = False)\n",
    "weekend.to_csv('theweekend_catalog', sep = ',', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
